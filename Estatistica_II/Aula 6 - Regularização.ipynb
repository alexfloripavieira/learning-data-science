{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "822ec564",
   "metadata": {},
   "source": [
    "# Aula 6 - Regularização\n",
    "\n",
    "Neste ponto, é muito importante que falemos sobre **regularização**.\n",
    "\n",
    "O objetivo da regularização é **diminuir a complexidade** de modelos, de modo a evitar que particularidades da base de treino (ruídos) sejam aprendidos (ou seja, evitar overfitting!)\n",
    "\n",
    "Uma outra forma de enxergar regularização: **diminuição do espaço de hipóteses!**\n",
    "\n",
    "<img src=https://curso-r.github.io/main-intro-ml/slides/static/img/erro_treino_erro_teste.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc80823",
   "metadata": {},
   "source": [
    "Regularização: problema de otimização VINCULADO!! ou seja, com restrições.\n",
    "\n",
    "problema de otimização: otimização da função de custo, que é o objetivo da aprendizagem, pra determinar o $\\hat{\\vec{b}}$\n",
    "\n",
    "restrições: é o que determina se temos L1 (lasso) ou L2 (ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba61633",
   "metadata": {},
   "source": [
    "### Regressão linear (sem regularização)\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/5408b0a7-85f3-4824-ad68-44867121ecb9.png width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9dabb",
   "metadata": {},
   "source": [
    "### L1 (Lasso)\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/acabe9da-07ba-4337-b467-dd2701a40cc8.png width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec298d",
   "metadata": {},
   "source": [
    "### L2 (Ridge)\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/46eda310-fb2f-498b-b455-593183de1dd7.png width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9db5d1",
   "metadata": {},
   "source": [
    "Para saber como relacionar $t$ com $\\lambda$, veja [este post](https://stats.stackexchange.com/questions/259177/expressing-the-lasso-regression-constraint-via-the-penalty-parameter) ou então [este](https://stats.stackexchange.com/questions/90648/kkt-versus-unconstrained-formulation-of-lasso-regression) -- discussões bem matemáticas!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c89bf",
   "metadata": {},
   "source": [
    "Observações importantes:\n",
    "\n",
    "- $\\lambda$ é um parâmetro que controla a \"força\" da regularização<br><br>\n",
    "- **L1 pode zerar coeficientes** - faz feature selection<br><br>\n",
    "- **L2 apenas diminui o tamanho de coeficientes** - não faz feature selection<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be885308",
   "metadata": {},
   "source": [
    "No sklearn, é possível fazer um modelo de regressão linear regularizado facilmente com as classes respectivas:\n",
    "\n",
    "- [Regularização L2/Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)\n",
    "\n",
    "- [Regularização L1/Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n",
    "\n",
    "Há, no sklearn, também uma implementação para um tipo de regularização conhecida como **Elastic Net**:\n",
    "\n",
    "A classe se chama [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f33a3b",
   "metadata": {},
   "source": [
    "Vamos utilizar regularização no dataset das casas, juntamente com as features polinomiais:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b565e",
   "metadata": {},
   "source": [
    "> **IMPORTANTE**: como os métodos de regularização são baseados na norma do vetor de parâmetros, é muito importante que as features sejam escaladas para que os métodos funcionem bem!\n",
    "\n",
    "Isso porque a escala das features irá influenciar a regularização aplicada ao parâmetro respectivo!\n",
    "\n",
    "Para eliminar este efeito, escalar os dados é muito importante!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e2ada",
   "metadata": {},
   "source": [
    "Vamos visualizar concretamente como a regularização de fato simplifica a hipótese! Pra isso, considere os pontos a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a094c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_regularized_reg(X, y, degree, \n",
    "                         type_regularization=None, alpha=1, l1_ratio=0.5, \n",
    "                         iter_max=1000):\n",
    "    '''\n",
    "    - type_regularization (str): opções de regularização: [\"l1\", \"l2\", \"en\", None]\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ======================================\n",
    " \n",
    "    pf = PolynomialFeatures(degree=degree, include_bias=False).fit(X_train)\n",
    "\n",
    "    # redefinindo as features de treino e de teste\n",
    "    X_train = pf.transform(X_train)\n",
    "    X_test = pf.transform(X_test)\n",
    "    \n",
    "    print(f\"Número original de features: {pf.n_features_in_}\")\n",
    "    print(f\"Número de features no espaço transformado: {pf.n_output_features_}\")\n",
    "\n",
    "    # ======================================\n",
    "    # normalização dos dados - MUITO importante quando há regularização!!\n",
    "    # e é o passo imediatamente antes de treinar os modelos\n",
    "    \n",
    "    mms = MinMaxScaler().fit(X_train)\n",
    "    \n",
    "    X_train = mms.transform(X_train)\n",
    "    X_test = mms.transform(X_test)\n",
    "    \n",
    "    # ======================================\n",
    "\n",
    "    if type_regularization == \"l1\":\n",
    "        \n",
    "        model = Lasso(alpha=alpha, max_iter=iter_max).fit(X_train, y_train)\n",
    "        \n",
    "    elif type_regularization == \"l2\":\n",
    "        \n",
    "        model = Ridge(alpha=alpha, max_iter=iter_max).fit(X_train, y_train)\n",
    "        \n",
    "    elif type_regularization == \"en\":\n",
    "        \n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=iter_max).fit(X_train, y_train)\n",
    "        \n",
    "    elif type_regularization == None:\n",
    "    \n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        list_opcoes = [\"l1\", \"l2\", \"en\", None]\n",
    "        raise ValueError(f\"Opção de regularização indisponível!\\nOpções aceitas: {list_opcoes}\")\n",
    "\n",
    "\n",
    "    # ======================================\n",
    "\n",
    "    # predições de treino\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    print(\"\\nMétricas de treino:\\n\")\n",
    "    print(f\"R^2: {r2_score(y_train, y_pred_train):.2f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_train, y_pred_train):.2f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}\")\n",
    "\n",
    "    # predições de teste\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    print(\"\\nMétricas de teste:\\n\")\n",
    "    print(f\"R^2: {r2_score(y_test, y_pred_test):.2f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred_test):.2f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"house_prices.csv\")\n",
    "df = df.select_dtypes(include=np.number).dropna()\n",
    "\n",
    "X = df.drop(columns=[\"SalePrice\", \"Id\"])\n",
    "y = df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressão linear, sem regularização\n",
    "# exatamente o que fizemos na primeira aula!\n",
    "poly_regularized_reg(X, y, degree=1, type_regularization=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69460e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=2, type_regularization=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd20ab",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=2, type_regularization=\"l1\", alpha=100, iter_max=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc331f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=3, type_regularization=\"l1\", alpha=100, iter_max=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1791cfb4",
   "metadata": {},
   "source": [
    "### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2466e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=2, type_regularization=\"l2\", alpha=200, iter_max=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=2, type_regularization=\"l2\", alpha=50, iter_max=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=3, type_regularization=\"l2\", alpha=50, iter_max=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6de36",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=2, type_regularization=\"en\", \n",
    "                     alpha=1, l1_ratio=0.5,\n",
    "                     iter_max=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9910c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=2, type_regularization=\"en\", \n",
    "                     alpha=10, l1_ratio=0.8,\n",
    "                     iter_max=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regularized_reg(X, y, degree=3, type_regularization=\"en\", \n",
    "                     alpha=100, l1_ratio=0.8,\n",
    "                     iter_max=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
